table(table_empr)
colnames(table_empr)
colnames(world_map)
merged_empres <- merge(world_map, table_empr, by.x="name", by.y="Country.region", all.x=TRUE)
plot(merged_empres['Ecologicalfootprint'])
full_bdd <- data.frame()
for (x in 1:35){
print(x)
page_x <- read_html(paste('https://www.gouvernement.fr/discours-et-rapports?page=',x,'&content_type%5B%5D=speech',sep=""))
Sys.sleep(2)
raw_list <- page %>%
html_nodes(css="div[class='fr-card__body']")
titles <- raw_list %>%
html_nodes(css="h4[class='fr-card__title fr-text-title--blue-france']") %>%
html_text() %>%
trimws()
dates <- raw_list %>%
html_nodes(css="div[class='fr-card__end']") %>%
html_nodes(css="p[class='fr-card__detail']") %>%
html_text()%>%
trimws() %>%
gsub("Publié ", "", .)
#html_attr("datetime")
category <- raw_list %>%
html_nodes(css="div[class='fr-card__start']") %>%
html_nodes(css="p[class='fr-card__detail']") %>%
html_text() %>%
trimws() %>%
substring(., 12)
links <- raw_list %>%
html_nodes(css="div[class='fr-card__content']") %>%
html_nodes(css="h4[class='fr-card__title fr-text-title--blue-france']") %>%
html_nodes('a') %>%
html_attr('href')
bdd_x <- data.frame(dates,
titles,
links)
full_bdd <- rbind(full_bdd,bdd_x)
}
library(rvest)
library(tidyverse)
library(stringr)
full_bdd <- data.frame()
for (x in 1:35){
print(x)
page_x <- read_html(paste('https://www.gouvernement.fr/discours-et-rapports?page=',x,'&content_type%5B%5D=speech',sep=""))
Sys.sleep(2)
raw_list <- page %>%
html_nodes(css="div[class='fr-card__body']")
titles <- raw_list %>%
html_nodes(css="h4[class='fr-card__title fr-text-title--blue-france']") %>%
html_text() %>%
trimws()
dates <- raw_list %>%
html_nodes(css="div[class='fr-card__end']") %>%
html_nodes(css="p[class='fr-card__detail']") %>%
html_text()%>%
trimws() %>%
gsub("Publié ", "", .)
#html_attr("datetime")
category <- raw_list %>%
html_nodes(css="div[class='fr-card__start']") %>%
html_nodes(css="p[class='fr-card__detail']") %>%
html_text() %>%
trimws() %>%
substring(., 12)
links <- raw_list %>%
html_nodes(css="div[class='fr-card__content']") %>%
html_nodes(css="h4[class='fr-card__title fr-text-title--blue-france']") %>%
html_nodes('a') %>%
html_attr('href')
bdd_x <- data.frame(dates,
titles,
links)
full_bdd <- rbind(full_bdd,bdd_x)
}
page_x <- read_html(paste('https://www.gouvernement.fr/discours-et-rapports?page=',x,'&content_type%5B%5D=speech',sep=""))
Sys.sleep(2)
raw_list <- page_x %>%
html_nodes('div')
raw_list <- page_x %>%
html_nodes(css="div[class='fr-card__body']")
titles <- raw_list %>%
html_nodes(css="h4[class='fr-card__title fr-text-title--blue-france']") %>%
html_text() %>%
trimws()
dates <- raw_list %>%
html_nodes(css="div[class='fr-card__end']") %>%
html_nodes(css="p[class='fr-card__detail']") %>%
html_text()%>%
trimws() %>%
gsub("Publié le ", "", .)
category <- raw_list %>%
html_nodes(css="div[class='fr-card__start']") %>%
html_nodes(css="p[class='fr-card__detail']") %>%
html_text() %>%
trimws() %>%
substring(., 12)
links <- raw_list %>%
html_nodes(css="div[class='fr-card__content']") %>%
html_nodes(css="h4[class='fr-card__title fr-text-title--blue-france']") %>%
html_nodes('a') %>%
html_attr('href')
bdd_x <- data.frame(dates,
titles,
category,
links)
full_bdd <- rbind(full_bdd,bdd_x)
full_bdd <- data.frame()
for (x in 1:35){
print(x)
page_x <- read_html(paste('https://www.gouvernement.fr/discours-et-rapports?page=',x,'&content_type%5B%5D=speech',sep=""))
Sys.sleep(2)
raw_list <- page_x %>%
html_nodes(css="div[class='fr-card__body']")
titles <- raw_list %>%
html_nodes(css="h4[class='fr-card__title fr-text-title--blue-france']") %>%
html_text() %>%
trimws()
dates <- raw_list %>%
html_nodes(css="div[class='fr-card__end']") %>%
html_nodes(css="p[class='fr-card__detail']") %>%
html_text()%>%
trimws() %>%
gsub("Publié le ", "", .)
#html_attr("datetime")
category <- raw_list %>%
html_nodes(css="div[class='fr-card__start']") %>%
html_nodes(css="p[class='fr-card__detail']") %>%
html_text() %>%
trimws() %>%
substring(., 12)
links <- raw_list %>%
html_nodes(css="div[class='fr-card__content']") %>%
html_nodes(css="h4[class='fr-card__title fr-text-title--blue-france']") %>%
html_nodes('a') %>%
html_attr('href')
bdd_x <- data.frame(dates,
titles,
category,
links)
full_bdd <- rbind(full_bdd,bdd_x)
}
write.csv2(full_bdd, 'full_bdd_speech_2024.csv')
for(row_x in 1:nrow(full_bdd)){
print(row_x)
speech_link <- paste('https://www.gouvernement.fr',full_bdd[row_x,"links"], sep="")
page_speech<- read_html(speech_link)
speech_x <- unlist(page_speech %>%
html_nodes(css="section[class='contents__content fr-mb-10w']") %>%
html_nodes(css="div[class='fr-col-lg-9 fr-col-offset-lg-1']") %>%
html_text()) %>%
trimws()
bdd1[row_x,'speech'] <- do.call(paste, c(as.list(speech_x), sep = " "))
Sys.sleep(2)
}
for(row_x in 1:nrow(full_bdd)){
print(row_x)
speech_link <- paste('https://www.gouvernement.fr',full_bdd[row_x,"links"], sep="")
page_speech<- read_html(speech_link)
speech_x <- unlist(page_speech %>%
html_nodes(css="section[class='contents__content fr-mb-10w']") %>%
html_nodes(css="div[class='fr-col-lg-9 fr-col-offset-lg-1']") %>%
html_text()) %>%
trimws()
bdd1[row_x,'speech'] <- do.call(paste, c(as.list(speech_x), sep = " "))
Sys.sleep(2)
}
for(row_x in 1:nrow(full_bdd)){
print(row_x)
speech_link <- paste('https://www.gouvernement.fr',full_bdd[row_x,"links"], sep="")
page_speech<- read_html(speech_link)
speech_x <- unlist(page_speech %>%
html_nodes(css="section[class='contents__content fr-mb-10w']") %>%
html_nodes(css="div[class='fr-col-lg-9 fr-col-offset-lg-1']") %>%
html_text()) %>%
trimws()
full_bdd[row_x,'speech'] <- do.call(paste, c(as.list(speech_x), sep = " "))
Sys.sleep(2)
}
print(row_x)
speech_link <- paste('https://www.gouvernement.fr',full_bdd[row_x,"links"], sep="")
page_speech<- read_html(speech_link)
page_speech
speech_x <- unlist(page_speech %>%
html_nodes(css="section[class='contents__content fr-mb-10w']") %>%
html_nodes(css="div[class='fr-col-lg-9 fr-col-offset-lg-1']") %>%
html_text()) %>%
trimws()
speech_x
do.call(paste, c(as.list(speech_x), sep = " "))
row_x=3
speech_link <- paste('https://www.gouvernement.fr',full_bdd[row_x,"links"], sep="")
page_speech<- read_html(speech_link)
speech_x <- unlist(page_speech %>%
html_nodes(css="section[class='contents__content fr-mb-10w']") %>%
html_nodes(css="div[class='fr-col-lg-9 fr-col-offset-lg-1']") %>%
html_text()) %>%
trimws()
full_bdd[row_x,'speech'] <- do.call(paste, c(as.list(speech_x), sep = " "))
speech_link
speech_x <- unlist(page_speech %>%
#html_nodes(css="section[class='contents__content fr-mb-10w']") %>%
html_nodes(css="div[class='fr-col-lg-9 fr-col-offset-lg-1']") %>%
html_text()) %>%
trimws()
speech_x
full_bdd[row_x,'speech'] <- do.call(paste, c(as.list(speech_x), sep = " "))
for(row_x in 1:nrow(full_bdd)){
print(row_x)
speech_link <- paste('https://www.gouvernement.fr',full_bdd[row_x,"links"], sep="")
page_speech<- read_html(speech_link)
speech_x <- unlist(page_speech %>%
#html_nodes(css="section[class='contents__content fr-mb-10w']") %>%
html_nodes(css="div[class='fr-col-lg-9 fr-col-offset-lg-1']") %>%
html_text()) %>%
trimws()
full_bdd[row_x,'speech'] <- do.call(paste, c(as.list(speech_x), sep = " "))
Sys.sleep(2)
}
full_bdd <- data.frame()
for (x in 1:36){
print(x)
page_x <- read_html(paste('https://www.gouvernement.fr/discours-et-rapports?page=',x,'&content_type%5B%5D=speech',sep=""))
Sys.sleep(2)
raw_list <- page_x %>%
html_nodes(css="div[class='fr-card__body']")
titles <- raw_list %>%
html_nodes(css="h4[class='fr-card__title fr-text-title--blue-france']") %>%
html_text() %>%
trimws()
dates <- raw_list %>%
html_nodes(css="div[class='fr-card__end']") %>%
html_nodes(css="p[class='fr-card__detail']") %>%
html_text()%>%
trimws() %>%
gsub("Publié le ", "", .)
#html_attr("datetime")
category <- raw_list %>%
html_nodes(css="div[class='fr-card__start']") %>%
html_nodes(css="p[class='fr-card__detail']") %>%
html_text() %>%
trimws() %>%
substring(., 12)
links <- raw_list %>%
html_nodes(css="div[class='fr-card__content']") %>%
html_nodes(css="h4[class='fr-card__title fr-text-title--blue-france']") %>%
html_nodes('a') %>%
html_attr('href')
bdd_x <- data.frame(dates,
titles,
category,
links)
full_bdd <- rbind(full_bdd,bdd_x)
}
write.csv2(full_bdd, 'full_bdd_speech_2024.csv')
for(row_x in 1:nrow(full_bdd)){
print(row_x)
speech_link <- paste('https://www.gouvernement.fr',full_bdd[row_x,"links"], sep="")
page_speech<- read_html(speech_link)
speech_x <- unlist(page_speech %>%
#html_nodes(css="section[class='contents__content fr-mb-10w']") %>%
html_nodes(css="div[class='fr-col-lg-9 fr-col-offset-lg-1']") %>%
html_text()) %>%
trimws()
full_bdd[row_x,'speech'] <- do.call(paste, c(as.list(speech_x), sep = " "))
Sys.sleep(2)
}
write.csv2(full_bdd, 'full_bdd_speech_2024.csv')
knitr::opts_chunk$set(echo = FALSE)
library(flextable)
library(dplyr)
library(magrittr)
# install.packages('tidytext')
library(tidytext)
#install.packages("tidyft") #Pour le recodage des variables textuelles
library(tidyft)
bdd_speech <- read.csv2('DATA/bdd_discours_2007_2022.csv') %>%
as.data.table() %>%
utf8_encoding(titles) %>%
utf8_encoding(dates) %>%
as.data.frame()
bdd_speech <- read.csv2('full_bdd_speech_2024.csv') %>%
as.data.table() %>%
utf8_encoding(titles) %>%
utf8_encoding(dates) %>%
as.data.frame()
head(bdd_speech$titles, n=6)
bdd_speech$titles <- gsub("[[:punct:]]", " ", bdd_speech$titles)
bdd_speech$titles <- gsub('[[:digit:]]+', '', bdd_speech$titles)
bdd_speech$titles <- gsub("[\r\n]", "", bdd_speech$titles)
head(bdd_speech$titles, n=4)
tidy_text <- tibble(bdd_speech) %>%
unnest_tokens("word", titles)
head(tidy_text, n=4)
bdd_speech
tidy_text <- tibble(bdd_speech) %>%
unnest_tokens("word", titles)
#install.packages("lsa") # packages pour le chargement de stopwords (pour différentes langues)
library(lsa)
data(stopwords_fr)
df_stopwords_fr <- data.frame(word=stopwords_fr,
lexicon = "?")
tidy_text <- tidy_text %>% dplyr::anti_join(df_stopwords_fr)
head(tidy_text, n=4)
head(tidy_text %>% dplyr::count(word, sort = TRUE))
new_stop_words_fr <- data.frame("word" = c("mme", "janvier", "février","mars","avril","mai","juin","juillet", "août", "septembre","octobre","novembre","décembre"), stringsAsFactors = FALSE)
tidy_text <- tidy_text %>% dplyr::anti_join(new_stop_words_fr)
head(tidy_text %>% dplyr::count(word, sort = FALSE))
knitr::opts_chunk$set(echo = FALSE)
library(flextable)
library(dplyr)
library(magrittr)
df_envi <- tidy_text_tfidf %>%
dplyr::filter(word=="environnement") %>%
dplyr::group_by(month_date) %>%
dplyr::summarise(sum_n = sum(n))
knitr::opts_chunk$set(echo = FALSE)
library(flextable)
library(dplyr)
library(magrittr)
"L'influence humaine a réchauffé l'atmosphère, l'océan et les terres."
ma_phrase <- "L'influence humaine a réchauffé l'atmosphère, l'océan et les terres."
is.character(ma_phrase)
nchar(ma_phrase) #nombre de caractères dans le string
#install.packages("stringr")
library(stringr)
str_detect(ma_phrase,"influence")
str_detect(ma_phrase,'calamar')
ma_phrase <- str_replace(ma_phrase,'humaine', "de l'homme")
ma_phrase <- gsub("'|,", " ", ma_phrase)
print(ma_phrase)
# install.packages('tidytext')
library(tidytext)
#install.packages("tidyft") #Pour le recodage des variables textuelles
library(tidyft)
bdd_speech <- read.csv2('full_bdd_speech_2024.csv') %>%
as.data.table() %>%
utf8_encoding(titles) %>%
utf8_encoding(dates) %>%
as.data.frame()
#head(bdd_speech$titles, n=6)
bdd_speech$titles <- gsub("[[:punct:]]", " ", bdd_speech$titles)
bdd_speech$titles <- gsub('[[:digit:]]+', '', bdd_speech$titles)
bdd_speech$titles <- gsub("[\r\n]", "", bdd_speech$titles)
head(bdd_speech$titles, n=4)
tidy_text <- tibble(bdd_speech) %>%
unnest_tokens("word", titles)
head(tidy_text, n=4)
#install.packages("lsa") # packages pour le chargement de stopwords (pour différentes langues)
library(lsa)
data(stopwords_fr)
df_stopwords_fr <- data.frame(word=stopwords_fr,
lexicon = "?")
tidy_text <- tidy_text %>% dplyr::anti_join(df_stopwords_fr)
head(tidy_text, n=4)
head(tidy_text %>% dplyr::count(word, sort = TRUE))
new_stop_words_fr <- data.frame("word" = c("mme", "janvier", "février","mars","avril","mai","juin","juillet", "août", "septembre","octobre","novembre","décembre"), stringsAsFactors = FALSE)
tidy_text <- tidy_text %>% dplyr::anti_join(new_stop_words_fr)
head(tidy_text %>% dplyr::count(word, sort = FALSE))
head(tidy_text %>% dplyr::count(word, sort = TRUE))
tidy_text_stems <- tidy_text %>%
mutate_at("word", funs(wordStem((.), language="fr")))
head(tidy_text_stems)
#install.packages("wordcloud")
library(wordcloud)
tidy_text %>%
dplyr::count(word) %>%
with(wordcloud(word, n, min.freq = 1000, colors = brewer.pal(8, "Dark2")))
new_stop_words_fr2 <- data.frame("word" = c("affaires","ministre", "ministres","communiqué","déclaration","conseil","secrétaire","interview","jean"), stringsAsFactors = FALSE)
tidy_text <- tidy_text %>% dplyr::anti_join(new_stop_words_fr2)
tidy_text_stems <- tidy_text %>%
mutate_at("word", funs(wordStem((.), language="fr")))
tidy_text_stems %>%
dplyr::count(word) %>%
with(wordcloud(word, n, min.freq = 900, colors = brewer.pal(8, "Dark2")))
tidy_text_tfidf <- tidy_text %>%
dplyr::count(word, dates) %>%
bind_tf_idf(word, dates, n) %>%
dplyr::arrange(desc(tf_idf))
head(tidy_text_tfidf)
tidy_text_tfidf$dates <- as.Date(tidy_text_tfidf$dates, format = c("%d %b %Y"))
tidy_text_tfidf$month <- paste("01/",format(tidy_text_tfidf$dates, "%m"),"/",format(tidy_text_tfidf$dates, "%Y"), sep="")
tidy_text_tfidf$month_date <- as.Date(tidy_text_tfidf$month, format=c('%d/%m/%Y'))
library(ggplot2)
tidy_text_tfidf %>%
dplyr::filter(month_date >= as.Date("2021-01-01")) %>%
dplyr::group_by(month_date) %>%
top_n(10, tf_idf) %>%
ungroup() %>%
dplyr::mutate(word = reorder(word, tf_idf)) %>%
ggplot(aes(word, tf_idf, fill = month_date)) +
geom_col(show.legend = FALSE) +
facet_wrap(~month_date, scales = "free") +
coord_flip()
library(ggplot2)
tidy_text_tfidf %>%
dplyr::filter(month_date >= as.Date("2021-01-01")) %>%
dplyr::group_by(month_date) %>%
top_n(10, tf_idf) %>%
ungroup() %>%
dplyr::mutate(word = reorder(word, tf_idf)) %>%
ggplot(aes(word, tf_idf, fill = month_date)) +
geom_col(show.legend = FALSE) +
facet_wrap(~month_date, scales = "free") +
coord_flip()
tidy_text_tfidf %>%
dplyr::filter(month_date >= as.Date("2021-01-01")) %>%
dplyr::group_by(month_date) %>%
top_n(10, tf_idf)
tidy_text_tfidf
tidy_text
tidy_text_tfidf <- tidy_text %>%
dplyr::count(word, dates) %>%
bind_tf_idf(word, dates, n) %>%
dplyr::arrange(desc(tf_idf))
tidy_text_tfidf
tidy_text_tfidf$dates <- as.Date(tidy_text_tfidf$dates, format = c("%d/%b/%Y"))
tidy_text_tfidf$dates
library(rvest)
library(tidyverse)
library(stringr)
url <- "https://en.wikipedia.org/wiki/List_of_countries_by_ecological_footprint"
code_html <- read_html(url, encoding="UTF-8")
code_html %>% html_nodes("title") %>% html_text()
tables <- code_html %>% html_nodes("main") %>% html_nodes("table")
table_empr <- as.data.frame(tables[3] %>% html_table(fill=TRUE))
table_empr <- table_empr[-c(1,2),]
library(sf)
world_map <- st_read('world-administrative-boundaries/world-administrative-boundaries.shp')
url <- "https://en.wikipedia.org/wiki/List_of_countries_by_ecological_footprint"
code_html <- read_html(url, encoding="UTF-8")
code_html %>% html_nodes("title") %>% html_text()
tables <- code_html %>% html_nodes("main") %>% html_nodes("table")
table_empr <- as.data.frame(tables[3] %>% html_table(fill=TRUE))
table_empr <- table_empr[-c(1,2),]
library(sf)
world_map <- st_read('world-administrative-boundaries/world-administrative-boundaries.shp')
plot(st_geometry(world_map))
merged_empres <- merge(world_map, table_empr, by.x="name", by.y="Country.region", all.x=TRUE)
merged_empres
list_countries <- subset(merged_empres, !is.na(Ecologicalfootprint))
list_countries <- subset(merged_empres, is.na(Ecologicalfootprint))$country
list_countries
list_countries <- subset(merged_empres, is.na(Ecologicalfootprint))$name
list_countries
world_map
table_empr
unique(table_empr$Country.region)
list_countries
plot(merged_empres['Ecologicalfootprint'])
table_empr <- table_empr %>%
mutate(Country.region = case_when(Country.region == "United States of America" ~ "United States"))
table_empr
table_empr <- as.data.frame(tables[3] %>% html_table(fill=TRUE))
table_empr <- table_empr[-c(1,2),]
library(sf)
world_map <- st_read('world-administrative-boundaries/world-administrative-boundaries.shp')
plot(st_geometry(world_map))
table_empr1 <- table_empr %>%
mutate(Country.region = case_when(Country.region == "United States of America" ~ "United States"))
table_empr1
table(table_empr1$Country.region)
table(table_empr$Country.region)
table_empr1 <- table_empr %>%
mutate(Country.region = case_when(Country.region == "United States" ~ "United States of America"))
table(table_empr1$Country.region)
schools$SchoolGenderID[schools$SchoolGenderID == "United States"] <- "United States of America"
table_empr$Country.region[table_empr$Country.region == "United States"] <- "United States of America"
table_empr$Country.region
merged_empres <- merge(world_map, table_empr, by.x="name", by.y="Country.region", all.x=TRUE)
list_countries <- subset(merged_empres, is.na(Ecologicalfootprint))$name
plot(merged_empres['Ecologicalfootprint'])
world_map
world_map$name
table_empr$Country.region[table_empr$Country.region == "United Kingdom"] <- "U.K. of Great Britain and Northern Ireland"
merged_empres <- merge(world_map, table_empr, by.x="name", by.y="Country.region", all.x=TRUE)
plot(merged_empres['Ecologicalfootprint'])
table_empr$Country.region[table_empr$Country.region == "Democratic Republic of the Congo"] <- "Congo, Democratic Republic of the"
merged_empres <- merge(world_map, table_empr, by.x="name", by.y="Country.region", all.x=TRUE)
plot(merged_empres['Ecologicalfootprint'])
table_empr$Country.region[table_empr$Country.region == "Congo, Democratic Republic of the"] <- "Democratic Republic of the Congo"
merged_empres <- merge(world_map, table_empr, by.x="name", by.y="Country.region", all.x=TRUE)
list_countries <- subset(merged_empres, is.na(Ecologicalfootprint))$name
plot(merged_empres['Ecologicalfootprint'])
table_empr$Country.region[table_empr$Country.region == "Russia"] <-"Russian Federation"
list_countries <- subset(merged_empres, is.na(Ecologicalfootprint))$name
merged_empres <- merge(world_map, table_empr, by.x="name", by.y="Country.region", all.x=TRUE)
list_countries <- subset(merged_empres, is.na(Ecologicalfootprint))$name
merged_emprs
plot(merged_empres['Ecologicalfootprint'])
Congo, Democratic Republic of the
table_empr$Country.region[table_empr$Country.region == "Libya"] <-"Libyan Arab Jamahiriya"
merged_empres <- merge(world_map, table_empr, by.x="name", by.y="Country.region", all.x=TRUE)
list_countries <- subset(merged_empres, is.na(Ecologicalfootprint))$name
merged_emprs
plot(merged_empres['Ecologicalfootprint'])
table_empr$Country.region[table_empr$Country.region == "South Korea"] <-"Republic of Korea"
merged_empres <- merge(world_map, table_empr, by.x="name", by.y="Country.region", all.x=TRUE)
list_countries <- subset(merged_empres, is.na(Ecologicalfootprint))$name
merged_emprs
plot(merged_empres['Ecologicalfootprint'])
table_empr$Country.region[table_empr$Country.region == "Tanzania"] <- "United Republic of Tanzania"
merged_empres <- merge(world_map, table_empr, by.x="name", by.y="Country.region", all.x=TRUE)
list_countries <- subset(merged_empres, is.na(Ecologicalfootprint))$name
merged_emprs
plot(merged_empres['Ecologicalfootprint'])
table_empr$Country.region
table_empr$Country.region
str(merged_empres)
merged_empres$Ecologicalfootprint <- as.numeric(merged_empres$Ecologicalfootprint)
plot(merged_empres['Ecologicalfootprint'])
